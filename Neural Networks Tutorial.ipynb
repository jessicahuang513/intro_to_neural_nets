{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Classic Neural Networks Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we'll be using Keras. Keras is like a higher-level abstraction of Tensorflow -- a popular ML library -- and will allow us to do some pretty cool stuff without knowing a lot of linear algebra/calculus. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fashion dataaset and model\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset - Fashion MNIST\n",
    "\n",
    "We'll be using labeled images of different types of clothing from MNIST (Modified National Institute of Standards and Technology database). They have a large database of handwritten digit images that I'm sure you've seen if you've gone through neural net examples in the past, but we'll be analyzing [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) for the following reasons:\n",
    "\n",
    "**1.** The MNIST digit dataset is too easy, and even classic ML algorithms can achieve 97% accuracy on this dataset.\n",
    "\n",
    "**2.** MNIST is overused.\n",
    "\n",
    "**3.** MNIST is not very representative of stuff you might actually do; i.e. bad ideas might work well on the digit dataset, but not on most other datasets.\n",
    "\n",
    "![title](img/fashion-dataset-ov.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Goal\n",
    "\n",
    "We want to turn each of these 28x28 pixel, grayscale images into one of 10 classifications:\n",
    "\n",
    "Label | Description\n",
    "--- | --- \n",
    "0 | T-shirt/top\n",
    "1 | Trouser\n",
    "2 | Pullover\n",
    "3 | Dress\n",
    "4 | Coat\n",
    "5 | Sandal\n",
    "6 | Shirt\n",
    "7 | Sneaker\n",
    "8 | Bag\n",
    "9 | Ankle Boot\n",
    "\n",
    "The dataset is already presplit into 60,000 training images and 10,000 testing images. These images are all labeled with their corresponding category (a number between 0 and 9). Let's get started by splitting the data into training, testing, and validation data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But before we start... what even *is* a neural net?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cat-net.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many people, this is what a neural net is: a black box that you feed an input (like an image, sequence of numbers, audio, etc), and it performs some kind of magic to correctly classify it or make a prediction.\n",
    "\n",
    "From a high level, that's actually very accurate. A simple neural network looks something like this:\n",
    "\n",
    "![title](img/neural-net.png)\n",
    "\n",
    "There are three parts:\n",
    "\n",
    "1. **Input Layer**: This is the actual data that you pass in. Usually this is a vector of numbers. For us, it would be some kind of numerical data that represents each pixel in the 28x28 images of clothing.\n",
    "2. **Hidden Layer**: This is an intermediate layer between the input and output layers. It is also where all the computation is done. There can be multiple hidden layers.\n",
    "3. **Output Layer**: The actual output of a neural network. For a classification problem, we want it to output a vector where one of the values is 1 (aka the neuron is lit up). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Neuron\n",
    "To better understand what kind of computation goes on inside hidden layers, let's take a look at a single neuron and contrast it to a biological neuron.\n",
    "\n",
    "![title](img/single_neuron.png)\n",
    "\n",
    "In biology, a neuron receives some kind of electrical signal from other neurons. If the signal is strong enough, it might be passed down the axon, and the neuron might \"fire\", meaning that it signals other neurons.\n",
    "\n",
    "Similarly, an artificial neuron gets a bunch of inputs (aka signals) from other neurons, calculates a weighted sum, adds a bias value, and passes that number into an activation function to determine whether how much the artificial neuron \"fires.\" \n",
    "\n",
    "Each connection between two neurons has a different weight. This is similar to biological neurons; paths between neurons that are fired more often together are \"stronger.\" In an artificial neural network, the higher the weight, the stronger the connection between the neurons. The bias value is similar to an intercept in a regression. It allows you to shift the activation function left or right.\n",
    "\n",
    "**Essentially, a neural network consists of many connected neurons. Thus, it is comprised of a series of these calculations where outputs are passed and altered from neuron to neuron until you reach the output layer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "\n",
    "An activation function is what determines whether the neuron \"fires\" or not. But what does that mean? Like we covered, a neuron does this calculation:\n",
    "\n",
    "![title](img/calculation.png)\n",
    "\n",
    "Y is a weighted sum plus a bias term. We pass Y into an activation function to determine whether it means the neuron should \"fire\" or not. But Y can be any value between negative and positive infinity. How does the neuron know what value means that it should fire? This is where an activation function comes in. Let's try several possibilities.\n",
    "\n",
    "#### Step Function\n",
    "\n",
    "The simplest example is a step function. If the input value is above a threshold, output 1 (\"fired\"). Else, output 0. At first, this seems great. We can transform values from (-inf, inf) into values {0, 1}. \n",
    "\n",
    "![title](img/step.png)\n",
    "\n",
    "However, this runs into the issue where you may have many neurons with the value of 1 at the same time. For example, if we get a vector with five 1s for our output layer, where each 1 refers to a type of clothing, how do we know which type it is? Thus, we need a function where activations aren't binary (ex: 20% activated, 66% activated).\n",
    "\n",
    "#### Linear Function\n",
    "\n",
    "Since the range of a linear function is between (-inf, inf), this doesn't confine our output values. In addition, the goal of an activation function is to introduce some non-linearity into our neural network.\n",
    "\n",
    "#### Sigmoid Function\n",
    "\n",
    "The sigmoid function is commonly used when you want to classify/output probabilities. It's range is between 0 and 1, and it commonly forces activations of the neuron to the extremes of the function (aka close to 0 or 1). However, this is also one of the problems of the sigmoid function: notice that toward the ends of the function, Y changes less as X changes. Thus, if your inputs get larger and larger, your output values may not change very much from layer to layer, which leads to slow learning. This is called **vanishing gradient.**\n",
    "\n",
    "![title](img/sigmoid.png)\n",
    "\n",
    "Because each activation function has pros/cons and best use cases, there are a lot that are used in practice (ReLu, tanh). Here's [more reading](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0) if you're interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "Backpropagation is basically gradient descent, but for neural networks. It is a way that we alter the weights, or the values associated with every connection between two neurons based on a cost function, like the squared error between desired and predicted output. It's called backpropagation because you move backward through the neural network as you update the weights.\n",
    "\n",
    "![title](img/backprop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The almighty perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/neural-net.png)\n",
    "\n",
    "This is a single layer perceptron. Notice the structure is a series of connected, feed-forward neurons (directed forward toward the output layer). We feed in data into the input layer, and the hidden layer neurons fire accordingly and communicate with the output layer.\n",
    "\n",
    "If you add more hidden layers, it becomes a **multilayer perceptron**, or MLP. Let's try using perceptrons to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening the data\n",
    "\n",
    "Notice the input layer is flat, whereas our data is 2D. How can we solve this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 60000 rows, where each row is a 2D picture (28 by 28) \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data from 2D to 1D:\n",
    "# reshape(__, -1) means that we're telling numpy that there are\n",
    "# two dimensions, and to \"infer\" the second dimension\n",
    "\n",
    "# we pass in x_train.shape[0], which means there will be 60000 rows\n",
    "# thus, numpy will \"infer\" that the length of each row will be 28x28 = 784\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0 # rgb is (0, 255)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "y_train = to_categorical(y_train) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note 28 * 28 = 784!\n",
    "# we've turned each picture into a 1D array of pixels\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28627451, 0.        , 0.        , 0.00392157, 0.01568627,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00392157])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0s for 9 categories that are not true for that picture, 1 for the right category\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Model\n",
    "\n",
    "We'll be using the ```Sequential``` model with ```Dense``` layers. This is used to create a perceptron-based neural network model. If you're curious, a ```Dense``` layer is just a regular NN layer for a multilayer perceptron that does: ```output = activation(weighted sum of inputs + bias)```.\n",
    "\n",
    "This means that it takes the dot product of your input vector and a weight vector for each neuron, and adds a bias. The dot product is a scalar value, meaning that it's not a vector (no direction). Finally, after taking the dot product, the Sequential Neural Network feeds this into an activation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Literally the simplest neural net model that Keras has\n",
    "# Sequential is a linear stack of layers\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layers to model\n",
    "\n",
    "# this is the hidden layer, which has 10 neurons, and 784 input values per neuron\n",
    "model.add(Dense(10, input_dim=784, activation='sigmoid'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 2.1314 - accuracy: 0.2876 - val_loss: 1.9468 - val_accuracy: 0.4535\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 1.7773 - accuracy: 0.5831 - val_loss: 1.6096 - val_accuracy: 0.6443\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 2s 38us/sample - loss: 1.4785 - accuracy: 0.6521 - val_loss: 1.3500 - val_accuracy: 0.6718\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 1.2589 - accuracy: 0.6728 - val_loss: 1.1626 - val_accuracy: 0.6873\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 1.1002 - accuracy: 0.6911 - val_loss: 1.0259 - val_accuracy: 0.7105\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.9830 - accuracy: 0.7114 - val_loss: 0.9254 - val_accuracy: 0.7397\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 3s 49us/sample - loss: 0.8939 - accuracy: 0.7334 - val_loss: 0.8467 - val_accuracy: 0.7493\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.8239 - accuracy: 0.7518 - val_loss: 0.7854 - val_accuracy: 0.7645\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.7681 - accuracy: 0.7664 - val_loss: 0.7376 - val_accuracy: 0.7757\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.7236 - accuracy: 0.7776 - val_loss: 0.6980 - val_accuracy: 0.7892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149c53f50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "_, test_acc1 = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7743\n"
     ]
    }
   ],
   "source": [
    "print(test_acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Intuition Behind the Model\n",
    "\n",
    "![title](img/tshirt-ex.png)\n",
    "\n",
    "Suppose we have a picture of a tshirt and a fully trained single layer perceptron neural network model. We feed the flattened 784 numbers of the image into the input layer. \n",
    "\n",
    "The goal is to have groups of neurons be able to \"recognize edges\" by firing when there is an edge in a certain area. For example, the group of pink neurons \"fire\" when the pink edge is present in the image. The group of blue neurons fire when the blue edge is present in the image. Then, in the output layer, a group of certain edges firing together should allow the neural network to determine what kind of clothing it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Layer Perceptron: Wider Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 3s 53us/sample - loss: 0.8380 - accuracy: 0.7301 - val_loss: 0.6021 - val_accuracy: 0.7845\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 2s 42us/sample - loss: 0.5507 - accuracy: 0.8139 - val_loss: 0.5204 - val_accuracy: 0.8177\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 2s 43us/sample - loss: 0.4988 - accuracy: 0.8288 - val_loss: 0.4816 - val_accuracy: 0.8307\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 2s 46us/sample - loss: 0.4731 - accuracy: 0.8371 - val_loss: 0.4625 - val_accuracy: 0.8368\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.4557 - accuracy: 0.8424 - val_loss: 0.4493 - val_accuracy: 0.8410\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 3s 59us/sample - loss: 0.4417 - accuracy: 0.8463 - val_loss: 0.4437 - val_accuracy: 0.8472\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 2s 43us/sample - loss: 0.4317 - accuracy: 0.8503 - val_loss: 0.4309 - val_accuracy: 0.8508\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.4217 - accuracy: 0.8548 - val_loss: 0.4324 - val_accuracy: 0.8505\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.4138 - accuracy: 0.8558 - val_loss: 0.4292 - val_accuracy: 0.8512\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.4061 - accuracy: 0.8589 - val_loss: 0.4445 - val_accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12c179750>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Widen network and use better activation\n",
    "model2 = Sequential()\n",
    "\n",
    "# 50 neurons in hidden layer\n",
    "model2.add(Dense(50, input_dim=784, activation='relu')) # relu is good for hidden layers\n",
    "\n",
    "# still 10 neurons in output layer\n",
    "model2.add(Dense(10, activation='softmax')) # softmax is good for output layers\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model2.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "_, test_acc2 = model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8325\n"
     ]
    }
   ],
   "source": [
    "print(test_acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 3s 61us/sample - loss: 0.5282 - accuracy: 0.8129 - val_loss: 0.4007 - val_accuracy: 0.8563\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 3s 60us/sample - loss: 0.3879 - accuracy: 0.8609 - val_loss: 0.3763 - val_accuracy: 0.8615\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 3s 52us/sample - loss: 0.3502 - accuracy: 0.8714 - val_loss: 0.3574 - val_accuracy: 0.8633\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 3s 58us/sample - loss: 0.3286 - accuracy: 0.8808 - val_loss: 0.3466 - val_accuracy: 0.8708\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 3s 52us/sample - loss: 0.3120 - accuracy: 0.8848 - val_loss: 0.3391 - val_accuracy: 0.8758\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.2987 - accuracy: 0.8900 - val_loss: 0.3467 - val_accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 3s 46us/sample - loss: 0.2879 - accuracy: 0.8923 - val_loss: 0.3451 - val_accuracy: 0.8737\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.2785 - accuracy: 0.8965 - val_loss: 0.3236 - val_accuracy: 0.8838\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 3s 48us/sample - loss: 0.2690 - accuracy: 0.9000 - val_loss: 0.3712 - val_accuracy: 0.8730\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 3s 47us/sample - loss: 0.2615 - accuracy: 0.9021 - val_loss: 0.3258 - val_accuracy: 0.8843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12ca947d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deeper \n",
    "model3 = Sequential()\n",
    "\n",
    "# 2 hidden layers\n",
    "model3.add(Dense(50, input_dim=784, activation='relu'))\n",
    "model3.add(Dense(50, activation='relu'))\n",
    "\n",
    "# 1 output layer\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# stochastic gradient descent. categorical_crossentropy is a loss function often used when\n",
    "# you have values that can only be in one category.\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "_, test_acc3 = model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8762\n"
     ]
    }
   ],
   "source": [
    "print(test_acc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs are out of the scope of this lecture, but I wanted to include them to show you how that more complicated neural network architectures exist, and you can use them to improve performance. You can think of CNNs as a more complex, deep learning architecture that does an operation called convolution, maxpooling and then before passing in data to a multilayer perceptron.\n",
    "\n",
    "Convolution allows you to extract \"hidden,\" higher-level features that are not immediately obvious from your input. \n",
    "\n",
    "![title](img/convolution.gif)\n",
    "\n",
    "Maxpooling reduces dimensionality, and also extracts the more dominant features. \n",
    "\n",
    "![title](img/pooling.gif)\n",
    "\n",
    "The outputs of these operations are then flattened (like we did before), and passed into a simple neural net for classification.\n",
    "\n",
    "![title](img/cnn.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train[:,:,:,np.newaxis] / 255.0\n",
    "x_test = x_test[:,:,:,np.newaxis] / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28, 1))) \n",
    "model4.add(MaxPooling2D(pool_size=2))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(10, activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                125450    \n",
      "=================================================================\n",
      "Total params: 125,770\n",
      "Trainable params: 125,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 25s 467us/sample - loss: 0.4444 - accuracy: 0.8457 - val_loss: 0.3367 - val_accuracy: 0.8783\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 22s 407us/sample - loss: 0.3156 - accuracy: 0.8885 - val_loss: 0.3046 - val_accuracy: 0.8913\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 23s 419us/sample - loss: 0.2827 - accuracy: 0.9004 - val_loss: 0.2910 - val_accuracy: 0.8962\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 22s 399us/sample - loss: 0.2610 - accuracy: 0.9072 - val_loss: 0.2848 - val_accuracy: 0.8970\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 21s 383us/sample - loss: 0.2458 - accuracy: 0.9130 - val_loss: 0.2888 - val_accuracy: 0.8987\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 22s 399us/sample - loss: 0.2315 - accuracy: 0.9171 - val_loss: 0.2753 - val_accuracy: 0.9045\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 21s 397us/sample - loss: 0.2195 - accuracy: 0.9205 - val_loss: 0.2759 - val_accuracy: 0.9018\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 21s 392us/sample - loss: 0.2083 - accuracy: 0.9257 - val_loss: 0.2820 - val_accuracy: 0.9045\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 22s 404us/sample - loss: 0.1979 - accuracy: 0.9289 - val_loss: 0.2730 - val_accuracy: 0.9075\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 22s 400us/sample - loss: 0.1881 - accuracy: 0.9331 - val_loss: 0.2747 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12ded2490>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "_, test_acc4 = model4.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8984\n"
     ]
    }
   ],
   "source": [
    "print(test_acc4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Keras and Tensorflow)",
   "language": "python",
   "name": "keras-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
